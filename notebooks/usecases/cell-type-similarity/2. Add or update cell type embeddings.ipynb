{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add/update embedding vectors for cell types\n",
    "\n",
    "##  (or any type of ontological classes)\n",
    "\n",
    "When adding a new set of embedding vectors or updating them, we need to perform the following sequence of steps\n",
    "\n",
    "1. Given a model id, its revision, and a given a set of resources, ask the service[or some python code] for embedding vectors\n",
    "2. Create/update embedding resources according to [this mapping](https://bbpgitlab.epfl.ch/dke/users/eugeniashurko/dataset-embeddings/-/blob/master/mappings/seu-embedding.hjson) --> model revision needs to be added to the `generation.activity.used.id`\n",
    "3. Push them to Nexus\n",
    "4. Tag them with the model UUID and the its revision (e.g. `e2b953b9-6724-4278-a1e5-3472bd63e374?rev=1`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related JIRA tickets: \n",
    "* https://bbpteam.epfl.ch/project/issues/browse/DKE-718\n",
    "* https://bbpteam.epfl.ch/project/issues/browse/DKE-715"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites:\n",
    "\n",
    "- The embedding model has been built\n",
    "- Embedding service can read models from a dedicated Nexus project where all models are stored (here, at the moment, we can download models locally and get vectors directly from the models, without using the service)\n",
    "- Model ID equals the Nexus resource id of the EmbeddingModel resource\n",
    "- __Important__: local contexts in the projects with vectors should contain:\n",
    "\n",
    "```\n",
    "{\n",
    "      \"embedding\": {\n",
    "        \"@id\": \"nsg:embedding\",\n",
    "        \"@container\": \"@list\"\n",
    "      }\n",
    "}\n",
    "```\n",
    "\n",
    "Questions:\n",
    "\n",
    "* do we really need to url-encode tags ?\n",
    "* add missing types and properties to the context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import getpass\n",
    "\n",
    "from kgforge.core import KnowledgeGraphForge\n",
    "from kgforge.core.resource import Resource\n",
    "\n",
    "from inference_tools.similarity.data_registration import (create_forge_session,\n",
    "                                                          load_embedding_models,\n",
    "                                                          push_embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kgforge.version import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"../../../configs/ontology-forge-config.yaml\"\n",
    "ENDPOINT = \"https://bbp.epfl.ch/nexus/v1\"\n",
    "# ENDPOINT = \"https://staging.nexus.ocp.bbp.epfl.ch/v1\"\n",
    "DOWNLOAD_DIR = \"../../../data\"\n",
    "TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bucket where embedding models live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_CATALOG_ORG = \"dke\"\n",
    "MODEL_CATALOG_PROJECT = \"embedding-pipelines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PROVIDE HERE THE IDs OF YOUR MODELs (OPTIONAL, REVISION)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID of the embedding models to use. For each type of taxonomy (mtype, ttype) we can have a list of embedding models representing different similarity aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_IDS = {\n",
    "    \"https://bbp.epfl.ch/ontologies/core/ttypes\": [\n",
    "        \"https://bbp.epfl.ch/nexus/v1/resources/dke/embedding-pipelines/_/d79a408f-3356-4e98-8998-df6720cac376\" # expression profile + taxonomy \n",
    "    ],\n",
    "    \"http://bbp.epfl.ch/neurosciencegraph/ontologies/mtypes\": [\n",
    "        \"https://bbp.epfl.ch/nexus/v1/resources/dke/embedding-pipelines/_/35681e34-5dea-45fa-82f1-511265dc238b\"  # morph features + taxonomy\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_REVISIONS = {}  # Specify a revision (key model_id, value revision number), if necessary.\n",
    "# If not specified the latest revision is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buckets where the input data lives together with the Bucket where the new embedding vectors should be registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_BUCKETS = {\n",
    "    (\"https://bbp.epfl.ch/nexus/v1\", \"neurosciencegraph\", \"datamodels\"): \n",
    "         (\n",
    "            \"https://bbp.epfl.ch/nexus/v1\",\n",
    "             \"neurosciencegraph\",\n",
    "             \"datamodels\"\n",
    "         )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the embedding endpoint/bucket are not specified, we assume that embeddings should live in the same bucket as the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forge sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session for embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forge_models = create_forge_session(\n",
    "    CONFIG_PATH,\n",
    "    (ENDPOINT, MODEL_CATALOG_ORG, MODEL_CATALOG_PROJECT),\n",
    "    TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions for different buckets for data and embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: find a way to pass different tokens and different configs\n",
    "FORGE_SESSIONS = {}\n",
    "for data_bucket, emb_bucket in DATA_BUCKETS.items():\n",
    "    if data_bucket not in FORGE_SESSIONS:\n",
    "        FORGE_SESSIONS[data_bucket] = create_forge_session(CONFIG_PATH, data_bucket, TOKEN)\n",
    "    if emb_bucket not in FORGE_SESSIONS:\n",
    "        FORGE_SESSIONS[emb_bucket] = create_forge_session(CONFIG_PATH, emb_bucket, TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_revisions = {}\n",
    "model_tags = {}\n",
    "pipelines = {}\n",
    "for ontology_id, ontology_models in MODEL_IDS.items():\n",
    "    revisions = MODEL_REVISIONS.get(ontology_id)\n",
    "    model_revisions[ontology_id], model_tags[ontology_id], pipelines[ontology_id] = load_embedding_models(\n",
    "        forge_models, ontology_models, model_revisions=revisions, dowload_dir=DOWNLOAD_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch resources from data buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type filter for generating embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_TYPE_FILTER = \"Class\"\n",
    "HARD_RESOURCE_LIMIT = 10000  # Limit on number of resources we can retrieve with SPARQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to register vectors only for existing classes, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resource_set = {}\n",
    "# for ontology_id in MODEL_IDS.keys():\n",
    "#     resource_set[ontology_id] = {}\n",
    "#     for bucket_config in DATA_BUCKETS.keys():\n",
    "#         if bucket_config not in resource_set:\n",
    "#             forge = FORGE_SESSIONS[bucket_config]\n",
    "#             query = f\"\"\"\n",
    "#                 SELECT ?id\n",
    "#                 WHERE {{\n",
    "#                     ?id a {DATA_TYPE_FILTER} ;\n",
    "#                         <http://www.w3.org/2000/01/rdf-schema#isDefinedBy> <{ontology_id}>;\n",
    "#                         <https://bluebrain.github.io/nexus/vocabulary/deprecated> false .\n",
    "#                 }}\n",
    "#             \"\"\" \n",
    "#             resources = forge.sparql(query, limit=HARD_RESOURCE_LIMIT)\n",
    "#             resources = [forge.retrieve(r.id) for r in resources] \n",
    "#             resource_set[ontology_id][bucket_config] = resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to register vectors for all points from the embedding model, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_set = {}\n",
    "for k, v in pipelines.items():\n",
    "    resource_set[k] = {}\n",
    "    for model in MODEL_IDS[k]:\n",
    "        for bucket in DATA_BUCKETS:\n",
    "            pipeline = pipelines[k][model]\n",
    "            resource_set[k][bucket] = [\n",
    "                Resource(id=el)\n",
    "                for el in pipeline.get_point_ids().tolist()\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in resource_set.items():\n",
    "    print(\"Ontology: \", k)\n",
    "    for kk, vv in v.items():\n",
    "        print(\"Bucket: \", kk)\n",
    "        print(\"\\t\", len(vv), \"resources\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embedding vectors for all the resources and push to Nexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO: add the NeuronMorphology revision once available\n",
    "- TODO: add prediction of previously unseen points (currently, only the in-sample points are considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEU_DICTIONARY_MAPPING = \"../../../mappings/seu-embedding.hjson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ontology_id, ontology_models in MODEL_IDS.items():\n",
    "    push_embedding_vectors(\n",
    "        FORGE_SESSIONS, DATA_BUCKETS, ontology_models,\n",
    "        model_revisions[ontology_id], model_tags[ontology_id],\n",
    "        pipelines[ontology_id], resource_set[ontology_id], SEU_DICTIONARY_MAPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tag should be used to create new ES views on the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bg",
   "language": "python",
   "name": "bg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
